program: main_finetune.py
method: grid
metric:
  name: val_auroc
  goal: maximize
description: sweep for ECG data from TCH 40 patients with Sinus and JET
project: adios_ecg-supervised-clocsCNN_1D-ECG_normalized-20230123_v30
name: supervised-clocsCNN_1D-ECG_normalized-20230604_v200-maxep200-early_stopping_patience40-mixup-label_smoothing-aug_selected_20221029_prob1.25-p0.01_0.1_0.2_0.5_1-k6
entity: yilongju # replace with your own wandb entity (username)
#entity: jspace # replace with your own wandb entity (username)
#early_terminate:
#  type: hyperband
#  min_iter: 2
#  eta: 2
parameters:
  name:
    value: "supervised-clocsCNN_1D-ECG_normalized-20230604_v200-maxep200-early_stopping_patience40-mixup-label_smoothing-aug_selected_20221029_prob1.25-p0.01_0.1_0.2_0.5_1-k6"
  dataset:
    value: "ecg-TCH-40_patient-20220201"
  cluster_name:
    value: "auto"
  stride:
    value: 2
  kernel_size:
    values: [6]
  aug_prob:
    values: [1.25]
  mixup_alpha:
    values: [0.2]
  label_smoothing:
    values: [0.2]
  transforms:
    values: ["SelectedAug_20221029"]
  batch_size:
    value: 128 # Should be halfed when transforms are used (effective batch size = batch_size * 2)
  seed:
    values: [0, 1, 2, 3, 4]
  training_data_frac:
    values: [0.01, 0.1, 0.2, 0.5, 1.0]
  lr:
    values: [0.01]
  optimizer:
    values: ["adam"]
  embedding_dim:
    values: [256]
  weight_decay:
    value: 1e-6
  max_epochs:
    value: 200
  patience:
    value: 40
  precision:
    value: 32
  lars:
    value: True
  exclude_bias_n_norm:
    value: True
  scheduler:
    values: ["warmup_cosine"]
  num_workers:
    value: 4
  wandb:
    value: True
  gpus:
    value: 0
  encoder:
    value: "clocs_cnn1d"
  ecg_resampling_length_target:
    value: 300
  ptl_accelerator:
    value: "ddp"
  sync_batchnorm:
    value: True
  accumulate_grad_batches:
    value: 1
  read_data_by_chunk:
    value: True
  data_chunk_folder:
    value: "ecg-pat40-tch-sinus_jet"
  shift_signal:
    value: False
  normalize_signal:
    value: True
  debug:
    value: False
  train_backbone:
    value: True